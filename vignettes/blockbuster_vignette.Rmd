---
title: "Blockbuster modelling: wow; what a difference!"
author: "Matthew Gregory"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{blockbuster_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

> Can I have a P please, Bob?.
([via](http://www.bbc.co.uk/news/entertainment-arts-16447409))

## Modelling  deterioration of the School Estate using Discrete-Time Markov chains

A useful package of functions and sample data to forecast the future condition of School blocks (or buildings) in the UK.

### Modelling overview

Markov chains represent a class of stochastic processes of great interest for the wide spectrum of practical applications. In particular, discrete time [Markov chains](https://cran.r-project.org/web/packages/markovchain/vignettes/an_introduction_to_markovchain_package.pdf) (DTMC) permit to model the transition probabilities between discrete states by the aid of matrices. The states are represented by the `grade` factor which is the surveyed condition of a building element, determined by a quantity surveyor through grades (states); N, A, B, C, D, E. The transition probabilities are 6 by 6 matrices with the average deterioration rate per timestep between states provided by expert building consultant opinion (see documentation for full details).  

### Business questions it can answer

This package is useful for decision makers as it provides a modelling approach for predicting the average condition of an individual building component (`elementid`) through time. This modelling approach can be scaled through a decision making hierarchy, with modelling the deterioration at the level of a School block (`buildingid`), for each site (`siteid`), the School (which may be made of many blocks, `urn`), at the Local Authority (LA) level (`lano`) and at the National level given suitable input data (filter desired rows using the `dplyr` package is recommended).  

The `blockbuster` function can be used on more than one row of what I call a `blockbuster_tibble` through more than one year, storing all the data of intermediary years. This flexibility allows decision makers to ask many and varied questions of the output data.  

## Loading the packages

Check you have these packages installed and then load them into memory using `library()` `require()`.

```{r warning=FALSE, message=FALSE, error=FALSE}
#  You could load tidyverse or you can load the individual packages, one-at-a-time.

library(dplyr)  #  need pipe %>%
library(ggplot2)  #  for visualisation
library(markovchain)  #  Recommended for markovchain S4 object handling (advanced).

library(blockbuster)  #  Required.

library(ggthemes)  #  Make pretty output with little effort.

```

## The initial state data

Provided with this package is some sampled data with identifying features removed. We suggest loading the `tidyverse` package when handling this data. This object is a tibble called by `blockbuster_pds`. For creating a subset of this data to make it manageable for simulation, use the [dplyr package](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html).  

The `areafy2` function was used on data queried from the Department for Education Education Funding Authority Property Data Survey SQL data tables (see 01_read_and_tidy_data.R for details). This provides estimates for the `unit_area` (a quantification of how much of a buildign component there is) variable. This is crucial for the DTMC methodology and for quantifying the costs of repairs.  

We take a look at the transpose of the data table which describes the dimensions of our sample data and the type of variables found therein.  

```{r}
dplyr::glimpse(blockbuster_pds)
```

## The transition probability data

The deterioration rates can be called by using either the tibble `blockbuster_det_data` or the `markovchainList` object `blockbuster_mc_list`. For example let's inspect an example of each.

```{r}
blockbuster_det_data[2, ]
```

This identifies the building component through the `element`, `sub_elment` and `const_type`. The "two-letter" variables describe the transition rate or probability from the first letter condition grade to the second letter condition grade. For example, for this building component (here `concated_det`), the `cd` describes the proportion of the `unit_area` at `grade == C` that will transition to `grade == D` through one timestep or year (`na` means from New to A (excellent condition) and is not to be confused with `NA`).  

```{r}
blockbuster_mc_list@markovchains[[2]]
# isS4(blockbuster_mc_list@markovchains[[1]])  #  TRUE
```

`blockbuster_mc_list` is a S4 object so the data needs to be accessed through its slots. They hold the same data in different ways. The S4 method may be useful in the future when incorporating some functions from the `markovchain` package.  

## The blockbuster functions

We consider the first row of this sampled data which is a roof of excellent `grade` A condition with a `unit_area` of 308.4.

```{r}

x <- blockbuster_pds[1, ]
dplyr::select(x, element, sub_element, const_type, grade, unit_area)

```

## Inspecting the associated deterioration rates

To determine which transition matrix is associated with each row we use the `det_what_tm()` function. This produces an error if the `markovchain` object does not exist. This works by concatenating the `element`, `sub_elment` and `const_type` and matching with the `concated_det` we saw earlier.  

```{r}
mc1 <- det_what_tm(x)
mc1
```

This is a `markovchain` object as described in the documentation of that package. It is a S4 object and we can access different components using slots and `[` sub-setting.

```{r}
mc1@transitionMatrix[, ]  #  [i, j] i for row, j column
```

## Deteriorating through time

Typically the user will be interested in a subset of the data. Consult the `dplyr` vignette for handling and sub-setting your data based on desired filter conditions.  

Here we demonstrate the deterioration of a single element through time. We chose a critical building feature of one particular block or building we are interested in.

```{r}
my_wall <- dplyr::filter(blockbuster_pds,
                         buildingid == 4382, sub_element == "Walls - Structure", 
                         const_type == "Brick / block")

my_wall_next_year <- blockbuster(my_wall, 1)
my_wall_next_year

my_wall_20year <- blockbuster(my_wall, 20)

```

This produces a [list of tibbles](https://twitter.com/hadleywickham/status/643381054758363136). Each tibble provides the condition of the input tibble at that timestep. Notice how the number of rows has increased. That's because we have a row for each `grade` state and associated `unit_area`. The first tibble in the list is for the input data or `timestep == 0`. It is prudent to check the timestep by inspecting it.

```{r}
my_wall_next_year[[2]]
head(my_wall_next_year[[2]]$timestep, 1)  #  1 timestep later than initial
```

## Blockbusting through many rows

The same principle applies as above where we pass the `blockbuster` function an input tibble object and the number of years into the future (relative to when the data was collected) we want to model to.

```{r}
y <- blockbuster_pds[1:20, ]  #  select all rows associated with decision level of interest, perhaps one block or one LA?
my_block_10years <- blockbuster(y, 10)
dplyr::select(my_block_10years[[11]],
              buildingid, elementid, grade, unit_area) %>%
  dplyr::arrange(elementid, grade)
```

## Computation time

I suggest you spend time thinking about the precise question you are asking rather than using the whole `blockbuster_pds` tibble as input due to non-trivial computation time. As a rule of thumb the amount of rows you start with will be multiplied by five (as each `elementid` deteriorates to other states), with each of these tibbles being multiplied by the `forecast_horizon`. That's quite a lot of data and may tax your computer's RAM (although the `unit_area`,  `timestep` and `cost` will be the only variables changing through time).  

## Plotting output basics

The tibble format is compatible with the `tidyverse` particularly `reshape2`-ing and plotting using `ggplot2`. The `purrr` package and the excellent `map_df()` function makes it easy to plot data from multiple dataframes across a list, as is the case with our `blockbuster` output.  

### Blockbusting

We can investigate the rate at which our critical elements are deteriorating or even what proportion of the `unit_area` is decommisioned. Given the flexibility of the model output we can ask anything of the data.  

Here we are interested in tracking the deterioration of critical building components in our block of interest.  We recycle the `my_wall_20year` object for this question. The wall starts as all condition grade B then gradually deteriorates.

```{r fig.width=9, fig.height=6}
p4 <- my_wall_20year %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(timestep, grade) %>%
  dplyr::summarise(sum_area = sum(unit_area, na.rm = TRUE)) %>%
  ggplot2::ggplot(aes(y = sum_area, x = grade)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(
    ~timestep
  )

p4 + ylab("Estimated area (m^2)") + xlab("Condition grade") +
  govstyle::theme_gov() 
```



### Critical building elements

Typically we may be more interested in critical, structural building-features such as the roof or walls and whether the `unit_area` exceeds a critical threshold determined by expert opinion. For example, is our wall's total `unit_area` after 10 years comprised of over 20% grade D and E? We plot then inspect the numbers.

```{r warning=FALSE, message=FALSE, error=FALSE, fig.width=9, fig.height=6}

my_wall_10 <- blockbuster(my_wall, 10)
#  We are interested in the 10 th (+ 1) timestep
df <- my_wall_10[[11]]

#  Use gov style for plot, install these if you don't have them
# devtools::install_github('mangothecat/visualTest')  #  required for govstyle
# devtools::install_github("UKGov-Data-Science/govstyle")

p <- ggplot2::ggplot(data = df, aes(x = grade, y = unit_area)) +
  ggplot2::geom_bar(stat = "identity", fill = govstyle::gov_cols['turquoise']) +
  xlab("Condition") +
  ylab(expression(paste(
  "Unit area (",m^2,
  ")", sep = ""))) +
  govstyle::theme_gov()

p 
```

We use `dplyr` to elucidate and determine that our wall is below our arbitrary 20% threshold, if we wanted to scale this we could create a new variable using `mutate` which is based on a logical test. The only limit is your imagination (and coding skills).

```{r}
total_wall_area <- sum(df$unit_area)
dplyr::mutate(df, prop_area = unit_area / total_wall_area) %>%
  dplyr::select(grade, unit_area, prop_area)
```

## Costing

The costing part of the `blockbuster` function is built using an internal function called `blockcoster_lookup`. This takes the building component and condition grade information and looks this character string up in the `blockbuster_pds_repair_costs` tibble, thus finding the appropriate repair costs constant to multiply the `unit_area` of that building component by.  

Originally it returned `NA` for grade E. This was due to lack of data on repairing a building component from grade E back to A, furthermore as grade E is meant to encapsulate a decommisioned status for now it was deemed more appropriate to only be able to get E back to grade N through rebuilding. However, user feedback suggested it more useful to attempt to approximate the grade E cost using a crude estiamte for now. This was achieved by modifying the code in `04_read_tidy_costs_data.R`. Costs for E are now simply the costs for D plus five percent. This approach was recommended by Adam Bray until we get empirical estimates.      

Costs are calculated for each row. The `cost_sum` variable is set to zero as this can be recalculated later if required, as it requires an aggregation by `buildingid` step (this is somewhat technical, see the `blockbuster` code by the costing step, where aggregation occurs).

### Blockcosting

We continue with the examples from above by considering the aggregated cost of repairs through time. Let us plot the distribution of costs by condition grade using a [Tukey box plot](https://en.wikipedia.org/wiki/Box_plot#Alternative_forms) through each year (R and ggplot make it easy to look at the data in different ways). Repair costs from grade A should always be zero as they are already in excellent condition and do not need any work. This plot shows how the median costs for each grade steadily increase year on year with some building components in particularly deteriorating quickly and in a costly fashion (the outliers indicated by the black circles). Note: the comments in the code are there to teach you the basis of this coding approach using the `map_df` function from the `purrr` package.  

#### Boxplot interpretation

The red "dots" at the end of the boxplot represent outliers. These observations contribute to the total cost of the block much more than others. There are a number of different rules for determining if a point is an outlier, but the method that R and ggplot use is the "1.5 rule". If a data point is:   
* `less than Q1 - 1.5 x IQR`  
* `greater than Q3 + 1.5 x IQR`  
then that point is classed as an "outlier". The line goes to the first data point before the "1.5" cut-off. Note: the inter-quartile range; `IQR = Q3 - Q1`.  
 
We have added a scattered jitterplot on top using `geom_point()` so that you can see how all the observations contribute to the observed `cost` distribution.  

```{r fig.width=9, fig.height=6}
#  http://www.machinegurning.com/rstats/map_df/

# 
# cool_cars <- list(mtcars, mtcars, mtcars) %>%
#   map_df(
#     ~ .x ,
#     .id = "year"
#   ) %>%
#   group_by("year") %>%
#   ggplot(aes(x = cyl, y = disp, group = cyl)) +
#   geom_boxplot() +
#   facet_wrap(
#     ~year
#   )
# cool_cars

p2 <- my_block_10years %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by("timestep") %>%
  ggplot2::ggplot(aes(x = grade, y = cost)) +
  ggplot2::geom_boxplot(outlier.colour = "red") +  #  Set to NA to avoid double plot
  ggplot2::facet_wrap(
    ~timestep
  )

p2 + ylab("Cost of repairs (£)") + xlab("Condition grade") +
  govstyle::theme_gov() + geom_point(position = position_jitter(width = 0.05),
                                     alpha = 0.15)

```

### Total Blockcosting

We take our hypothetical building and plot the total costs year on year by condition grade. Notice how the costs to repair the hypothetical block increases, accelerating as more and more `unit_area` gets into grade E.

```{r fig.width=9, fig.height=6}
p3 <- my_block_10years %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(timestep, grade) %>%
  dplyr::summarise(sum_cost = sum(cost, na.rm = TRUE)) %>%
  ggplot2::ggplot(aes(x = grade, y = sum_cost)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(
    ~timestep
  )

p3 + ylab("Total cost of repairs (£)") + xlab("Condition grade") +
  govstyle::theme_gov() 
```

### Line plot

The blockbuster output is flexible and amenable to data manipulation and or transformation prior to plotting. The user is only limited by their imagination.  

Below we present a standard output that is seen in many reports of the School Estate. Here we plot the total costs by aggregated by condition grade for each year and give it a slightly prettier finish. Note how the condition `grade` A do not contribute to the cost. However, the repair cost of E (set at D repair cost plus five percent) accelerates the total cost as more building components' `unit_area` transitions into grade E from D. It's important users are aware of this when interpretating these graphics as the estiamted cost of B, C and D should be considered more reliable as they are based on expert opinion and bespoke costs for each building component (whereas E grade is just 5% on D which may not be appropriate for every building component).     

```{r fig.width=9, fig.height=6}

p4 <- my_block_10years %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(timestep, grade) %>%
  dplyr::summarise(sum_cost = sum(cost, na.rm = TRUE)) %>%
  ggplot2::ggplot(aes(x = timestep, y = sum_cost, group = grade, colour = grade)) +
  ggplot2::geom_line(size = 1.3) 
  

p4 + ylab("Total cost of repairs (£)") + xlab("Years after PDS") +
  govstyle::theme_gov() +
  theme(legend.position = "bottom") +
  # ggthemes::theme_hc() + ggthemes::scale_colour_hc() +
  ggtitle("Cost of repairs through time for our example block")

```

### Digging down

> Better to draw several approximate graphics saying something about the right question than to draw one precise graphic relating to the wrong question.

The `blockbuster` simulation is time expensive thus we do not want ot generate every possible outcome variable that a user might need. Instead we generate variables that are required for the simulation, for decision making regarding which blocks should be rebuilt or repaired. Instead you can derive variables yourself. Be imaginative and try plenty of variety in your plots.

### Costing the rebuilding of a block

The repair costs had previously ignored decommisioned building components (grade E `unit_area` of a building component). To incorporate this into our analysis of when it is better to rebuild a block rather than to maintain it we create a new variable in the `blockbuster_tibble` called `block_rebuild_cost`. This multiplies the `gifa`, of the block that the building component in question is part of, by the argument (blockbuster input) `rebuild_cost_rate` (this has a default value). This does not fully capture the complexity of estimating the rebuild cost of a block and could be enhanced in future iterations of the `blockbuster`. At the moment it can accept a constant `rebuild_cost_rate` or varying `rebuild_cost_rate` (a vector the same length as the argument `forecast_horizon` that can adjust for inflation). This value is the same for all building components in the same block as it is a function of the block's `gifa` (it only makes sense considered at the block level).  

```{r}
two_blocks_4_years_inflation <- blockbuster(dplyr::filter(blockbuster_pds,
                                                              buildingid == 4382 |
                                                                buildingid == 4472),
                                                forecast_horizon = 4,
                                                rebuild_cost_rate = c(1274, 1281, 1289, 1296) 
                                                )

two_blocks_4_years_inflation %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(buildingid, timestep, block_rebuild_cost) %>%
  dplyr::tally()

```

#### Total costs by building element

```{r fig.width=9, fig.height=6}
p5 <- my_block_10years %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(timestep, element) %>%
  dplyr::summarise(sum_cost = sum(cost, na.rm = TRUE)) %>%
  ggplot2::ggplot(aes(x = element, y = sum_cost)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(
    ~timestep
  )

p5 + ylab("Total cost of repairs (£)") + xlab("Building element") +
  govstyle::theme_gov() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  theme(plot.margin = unit(c(20,10,10,10),"mm"))

```

#### Subsetting the blockbuster list output for specified years of interest

Perhaps we are interested in just the last couple of years of the simulation? We can subset a single year of interest or dataframe from the list using the normal R syntax.  

The following graph also highlights a flaw in the earlier generation of the deterioration model which just considered the `unit_area` of a building component and ignored the building component `element`, `sub_element` or `const_type` type in its calculations. The blockbuster model considers this when estimating repair costs. In the figure below we aggregate across building `element` the total `unit_area` and `cost` of repairs and plot using the extra dimensions afforded by point area and colour. In short this identifies an interaction term between `element` and `grade` for `cost` of repairs (the trajectory of gradient is different between building components as you go between condition grades).    

```{r fig.width=9, fig.height=6}
p6 <- my_block_10years[11] %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(timestep, grade, element_shrt = as.factor(abbreviate(element, 14))) %>%
  dplyr::summarise(sum_unit_area = sum(unit_area, na.rm = TRUE),
                   sum_cost = sum(cost, na.rm = TRUE)) %>%
  ggplot2::ggplot(aes(x = grade, y = sum_cost, colour = element_shrt, size = sum_unit_area)) +
  ggplot2::geom_point(alpha = 0.7) +
  ggplot2::facet_wrap(
    ~ timestep
  )

p6 + ylab("Cost of repairs (£)") + xlab("Condition grade")  +
  theme_economist() + 
  scale_size_continuous(breaks = c(1000, 2000, 3000), range = c(3,10))

```

## Rebuilding

Rebuilding is carried out by the `rebuild` function which is internal to `blockbuster`. The rebuilding of the `blockbuster_tibble` you pass as an argument is dependent on two other arguments; the `rebuild_monies` and `rebuild_cost_rate`. Both can be passed as a vector equal in length to the number of years you are simulating (`forecast_horizon`) or as a number. This allows you to control for inflation in the construction industry and variable rebuilding spending from year to year. Technically the `blockbuster` function makes use of the `rebuild_cost_rate` in estimating how much it would cost to rebuild a block (`rebuild_cost_rate` multiplied by block `gifa`), this is then passed into `rebuild` for a decision on how to spend the available `rebuild_monies`. All the blocks (unique based on `buildingid`) in the `blockbuster_tibble` are ranked in descending order of the ratio of the total cost of repairs to the cost of rebuilding the block (where a score higher than one means the block is more expensive to repair than it is to rebuild). The block with the highest internal statistic of `cost_to_rebuild_ratio` is inspected for rebuilding first. If enough monies are available it is rebuilt by converting all its building components back to new and recalculating the `unit_area` (using `areafy2`). The leftover money is then cycled through the list rebuilding as appropriate until the remaining money is less than the cheapest block to rebuild, at which point it is discarded (NOT passed to `repair_monies`).  

### Example

We inspect the effect of rebuilding on the cost of repairs of three buildings with a non-constant rebuilding investment profile and `rebuild_cost_rate` adjusted for 0% (year 2) then 1% inflation (year 3) (you can pass this as a vector rather than typing it manually of course). We inspect the effect of the rebuild on total repair costs using a faceted stacked bar chart for the different building elements in all the blocks (try increasing the `rebuild_monies` by one pound, what happens?).

```{r fig.width=9, fig.height=9}
#  We filter our PDS sample for just three blocks to keep things simple
x <- dplyr::filter(blockbuster::blockbuster_pds,  buildingid == 4382 | buildingid == 4472
                   | buildingid == 4487)
#  Rebuild spending profile
y <- blockbuster(x, forecast_horizon = 3, rebuild_monies = c(0, 5e6, 0),  #  five million
                 rebuild_cost_rate = c(1274, 1274 + 0, 1274 + 12.74))  #  £/m^2

p7 <- y %>%
  purrr::map_df(
    ~ .x ,
    .id = NULL
  ) %>%
  dplyr::group_by(timestep, element, grade) %>%
  dplyr::summarise(sum_cost = sum(cost, na.rm = TRUE)) %>%
  ggplot2::ggplot(aes(x = element, y = sum_cost, fill = grade)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(
    ~timestep
  ) + scale_fill_discrete(drop = FALSE) + scale_x_discrete(drop = FALSE)  #  gives E a colour

p7 + ylab("Total cost of repairs (£)") + xlab("Building element") +
  govstyle::theme_gov() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  theme(plot.margin = unit(c(20,10,10,10),"mm")) +
  theme(legend.position = "top") 
```

This also provides a sense check. The rebuild happens during `timestep 2` (because `rebuild_monies = c(0, 5e6, 0)`), all building components are rebuilt to `grade = N` thus have  zero `cost`. During the next timestep there will be some deterioration to `grade = A`, however all building components of excellent condition do not contribute to the repair costs of a block, hence no cost of repairs in `timestep 3`.

## Repairs

## Summary

* This modelling approach has the potential to make use of all the data.  
* It uses a robust statistical modelling approach.  
* The input structure is preserved in the output tibbles.  
* The model can be iteratively improved as more data is collected.  
* There is flexibility in the transition matrices that are used that should be estimated empirically in the future, data collection permitting.
* The writing of a package allows us to enshrine business knowledge into a corpus of code that is inseparable from the documentation of that code.

```{r}
sessionInfo()
```
